{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "asigmo_ex4_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahnazshamissa/Python/blob/main/asigmo_ex4_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLvl9qZpRR1A"
      },
      "source": [
        "# Exercise 4\n",
        "\n",
        "\n",
        "Per group create a teams-meeting where one person opens the colab notebook and shares the screen (preferably a different person than yesterday)\n",
        "\n",
        "1.   Change the data source from \"frankenstein.txt\" to \"dracula.txt\", \n",
        "2.   Train the network for 10 epochs and test it on the 3 example sentences\n",
        "3.   Write down 3 more example sentences and test the model on these as well\n",
        "4.   Train the LSTM for 50 more epochs and run the completion again. What do you observe?\n",
        "4.   Add another LSTM layer to our RNN model\n",
        "5.   Train the 2-layer LSTM for 10 epochs and see how the sentence completion has changed\n",
        "6.   Change the \"dracula.txt\" to \"trump.txt\", which contains Tweets from Donald Trump from 2019 and 2020.\n",
        "7.   Train a single-layer LSTM on the Tweet's from Trump. If you run out of memory while preprocessing the data, change ```step = 3``` to ```step = 10```.\n",
        "8.   Run the completion on the six sentences from before again. What do you observe?\n",
        "\n",
        "\n",
        "\n",
        "**Question**\n",
        "The models make very few spelling errors and few grammar error, but the content is mostly nonsense. Why do you think are the error types so different?\n",
        "\n",
        "We will meet in the general channel at 12:10!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A4xscds3KtQ",
        "outputId": "5b571a3f-e3b1-4895-fe3e-2879b855ed04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Oct 30 10:13:26 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     7W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTLXcbOl3n2E"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He7DevTX5gcs"
      },
      "source": [
        "# Downloading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhAlKCjm5f0b",
        "outputId": "ece49bae-b57e-406e-aff3-40b62badeff3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "filename = \"dracula.txt\"\n",
        "path = tf.keras.utils.get_file(\n",
        "    filename, origin=f\"https://pub.ist.ac.at/~mlechner/datasets/{filename}\"\n",
        ")\n",
        "with open(path, encoding=\"utf-8\") as f:\n",
        "    text = f.read().lower()           # Make lowercase \n",
        "text = text.replace(\"\\n\", \" \")        # Remove line-breaks & newlines\n",
        "print(\"Corpus length:\", len(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://pub.ist.ac.at/~mlechner/datasets/dracula.txt\n",
            "860160/857524 [==============================] - 1s 1us/step\n",
            "Corpus length: 842159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtFFQXZB5pfj",
        "outputId": "e264714e-069c-4cda-a81c-844d150b8466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Print the first 100 characters of the file we downloaded\n",
        "print(\"First 100 characters: \",text[:100])\n",
        "print(\"Last 100 characters : \",text[-100:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 100 characters:  dracula, by bram stoker  chapter i  jonathan harker's journal  (_kept in shorthand._)   _3 may. bist\n",
            "Last 100 characters :  will understand how some men so loved her, that they did dare much for her sake.\"  jonathan harker. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ6Kxxoo6Pg1"
      },
      "source": [
        "# Define input features and output labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFTI5-543yKi",
        "outputId": "9c10bdf3-7726-40e7-c458-b0fb0c95431c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print(\"Total chars:\", len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "maxlen = 50\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i : i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print(\"Number of sequences:\", len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total chars: 64\n",
            "Number of sequences: 280703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z75uMG-35Ihz",
        "outputId": "39577b4e-cbb0-41b5-aba5-673484cd9410",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"First sentence:\")\n",
        "print(sentences[0])\n",
        "print(\"First label: \")\n",
        "print(next_chars[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First sentence:\n",
            "dracula, by bram stoker  chapter i  jonathan harke\n",
            "First label: \n",
            "r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eIkuFt65aQF"
      },
      "source": [
        "# Transforming text into numerical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJP69sDV5VGj"
      },
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros(len(sentences), dtype=np.int32)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i] = char_indices[next_chars[i]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KbhiVJ140xE",
        "outputId": "57904eda-8c83-4fb7-8740-73597116e246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# First training samples\n",
        "print(x[0])\n",
        "print(\"label: \")\n",
        "print(y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " ...\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]\n",
            " [False False False ... False False False]]\n",
            "label: \n",
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwfhq3pnEBit"
      },
      "source": [
        "# Splitting training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW4OyUE4DZS9",
        "outputId": "41715f5c-dd21-4c6c-d0d5-fe11ab46d276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# We can define our training and validation dataset as simple numpy arrays\n",
        "split_index = int(0.2*x.shape[0])\n",
        "valid_x, valid_y = x[-split_index:],y[-split_index:]\n",
        "train_x, train_y = x[:-split_index],y[:-split_index]\n",
        "print(\"valid_x.shape\",valid_x.shape)\n",
        "print(\"valid_y.shape\",valid_y.shape)\n",
        "print(\"train_x.shape\",train_x.shape)\n",
        "print(\"train_y.shape\",train_y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "valid_x.shape (56140, 50, 64)\n",
            "valid_y.shape (56140,)\n",
            "train_x.shape (224563, 50, 64)\n",
            "train_y.shape (224563,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCurnl9YOAM1"
      },
      "source": [
        "# Defining our Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Se-1ndKD4E4i",
        "outputId": "b7e5fefe-be66-441d-a329-f8c92dc9f321",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(maxlen, len(chars))),\n",
        "        tf.keras.layers.LSTM(32,return_sequences=True),\n",
        "        tf.keras.layers.LSTM(32),\n",
        "        tf.keras.layers.Dense(len(chars), activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,metrics=[\"sparse_categorical_accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_9 (LSTM)                (None, 50, 32)            12416     \n",
            "_________________________________________________________________\n",
            "lstm_10 (LSTM)               (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 64)                2112      \n",
            "=================================================================\n",
            "Total params: 22,848\n",
            "Trainable params: 22,848\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZ0PMEJlRDyd"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1NLlj4z4bkK",
        "outputId": "a370c629-882a-4117-d285-9758eaf8ba68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_log = model.fit(train_x, train_y, batch_size=64, epochs=10, validation_data=(valid_x,valid_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3509/3509 [==============================] - 28s 8ms/step - loss: 28.1523 - sparse_categorical_accuracy: 0.1296 - val_loss: 18.4078 - val_sparse_categorical_accuracy: 0.1338\n",
            "Epoch 2/10\n",
            "3509/3509 [==============================] - 28s 8ms/step - loss: 12.7606 - sparse_categorical_accuracy: 0.1979 - val_loss: 11.3592 - val_sparse_categorical_accuracy: 0.2374\n",
            "Epoch 3/10\n",
            "3509/3509 [==============================] - 27s 8ms/step - loss: 7.6625 - sparse_categorical_accuracy: 0.2393 - val_loss: 5.5947 - val_sparse_categorical_accuracy: 0.2330\n",
            "Epoch 4/10\n",
            "3509/3509 [==============================] - 28s 8ms/step - loss: 3.9261 - sparse_categorical_accuracy: 0.2833 - val_loss: 4.8535 - val_sparse_categorical_accuracy: 0.2841\n",
            "Epoch 5/10\n",
            "3509/3509 [==============================] - 28s 8ms/step - loss: 3.0826 - sparse_categorical_accuracy: 0.3259 - val_loss: 2.1112 - val_sparse_categorical_accuracy: 0.4129\n",
            "Epoch 6/10\n",
            "3509/3509 [==============================] - 29s 8ms/step - loss: 1.9893 - sparse_categorical_accuracy: 0.4341 - val_loss: 1.9341 - val_sparse_categorical_accuracy: 0.4473\n",
            "Epoch 7/10\n",
            "3509/3509 [==============================] - 28s 8ms/step - loss: 1.9003 - sparse_categorical_accuracy: 0.4576 - val_loss: 1.8734 - val_sparse_categorical_accuracy: 0.4618\n",
            "Epoch 8/10\n",
            "3509/3509 [==============================] - 27s 8ms/step - loss: 1.9086 - sparse_categorical_accuracy: 0.4661 - val_loss: 1.8158 - val_sparse_categorical_accuracy: 0.4690\n",
            "Epoch 9/10\n",
            "3509/3509 [==============================] - 28s 8ms/step - loss: 1.8513 - sparse_categorical_accuracy: 0.4727 - val_loss: 1.8803 - val_sparse_categorical_accuracy: 0.4690\n",
            "Epoch 10/10\n",
            "3509/3509 [==============================] - 28s 8ms/step - loss: 1.8374 - sparse_categorical_accuracy: 0.4776 - val_loss: 1.8622 - val_sparse_categorical_accuracy: 0.4722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-F2scl-RFjz"
      },
      "source": [
        "# Let's try out our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGqx_9q-A6kb"
      },
      "source": [
        "def sample(preds, temperature=0.5):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "    \n",
        "def complete_sentence(sentence):\n",
        "  if len(sentence) < maxlen:\n",
        "    raise ValueError(f\"Sentence must have at least {maxlen} characters, but provided sentence had only {sentence}\")\n",
        "  if len(sentence) > maxlen:\n",
        "    sentence = sentence[-maxlen:]\n",
        "  generated = \"\"\n",
        "  print(f\"Continuing sentence '{sentence}' ...\")\n",
        "\n",
        "  for i in range(200):\n",
        "      x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "      for t, char in enumerate(sentence):\n",
        "          x_pred[0, t, char_indices[char]] = 1.0\n",
        "      preds = model.predict(x_pred, verbose=0)[0]\n",
        "      next_index = np.argmax(preds) # next_index = sample(preds)\n",
        "      next_char = indices_char[next_index]\n",
        "      sentence = sentence[1:] + next_char\n",
        "      generated += next_char\n",
        "\n",
        "  print(\"... \", generated)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZAW4zpVBgzj",
        "outputId": "ac056124-2736-4a06-de52-4b6c8363fc3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "complete_sentence(\"this is an example to show how the machine would continue\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Continuing sentence ' an example to show how the machine would continue' ...\n",
            "...   to the stoust the stoust the stoust the stoust the stoust the stoust the stoust the stoust the stoust the stoust the stoust the stoust the stoust the stoust the stoust the stoust the stoust the stous\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLo3EBGCFble",
        "outputId": "c45283da-e9a2-46a5-865b-58d4a1b9d27c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "complete_sentence(\"I want to play football with ronaldo because i always liked him as a footballer\")\n",
        "complete_sentence(\"I want to play football with ronaldo because i always liked him as a footballer\")\n",
        "complete_sentence(\"I want to play football with ronaldo because i always liked him as a footballer\")\n",
        "complete_sentence(\"I want to play cricket with dhoni because i always liked him as a cricketer\")\n",
        "complete_sentence(\"I want to play bawling with cummins because i always liked him as a bowling\")\n",
        "complete_sentence(\"Tvbhjjbjbjbbab nv anhvhaghchvdejbbdmn nc n  nac xn jcjb jcejb  eacn cc  acc\")\n",
        "complete_sentence(\"jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Continuing sentence 'ronaldo because i always liked him as a footballer' ...\n",
            "...   of the an ording with a she will have made the sight. the solerable of the death i saw the horrid strong and the short and the corner that so that i did startle of to see it with it. i must be the mi\n",
            "\n",
            "Continuing sentence 'ronaldo because i always liked him as a footballer' ...\n",
            "...  s room and the night, but one of the start are according the sight and the horrid or great with the night. he was the words of his stative fellown and a dear, and he was enterrast on the lething that \n",
            "\n",
            "Continuing sentence 'ronaldo because i always liked him as a footballer' ...\n",
            "...   the other and seemed to the kind. i keep it is one time and that i could see her or working his death. the a sperhode of the softice dided and he was when stent that i sutterened and go on, the words\n",
            "\n",
            "Continuing sentence 'th dhoni because i always liked him as a cricketer' ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "...  ich that i have had so crednt the sound, of the body and darked that the some one since in the hing in the door still a orounient of look which had a seeming and avolding the sight; and then van her, \n",
            "\n",
            "Continuing sentence 'th cummins because i always liked him as a bowling' ...\n",
            "...   of the engle, and like the death--he all it all the patient of polling at one best.  \"we not be indeet we will let me affard. i thought had have looked the despolling, as the street of a man as it wa\n",
            "\n",
            "Continuing sentence 'hchvdejbbdmn nc n  nac xn jcjb jcejb  eacn cc  acc' ...\n",
            "...  ation. they can see the hesse did\"able of more one as i had in be despaige. and i shall one for her afternoon bent thing and seeming the morning of her door of the time. the patow will comes had been \n",
            "\n",
            "Continuing sentence 'jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj' ...\n",
            "...  eu\"tatch his sighters. i shall such an about the sortion of the since.         *       *       *       *       *       *       *       *       *       *       *       *       *       *       *       *\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ebL_j9NNzd",
        "outputId": "37185931-b93b-4d5b-ce0b-27c82bb21d6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "complete_sentence(\"I want to play football with ronaldo because i always liked him as a footballer\")\n",
        "complete_sentence(\"I want to play football with ronaldo because i always liked him as a footballer\")\n",
        "complete_sentence(\"I want to play football with ronaldo because i always liked him as a footballer\")\n",
        "complete_sentence(\"I want to play cricket with dhoni because i always liked him as a cricketer\")\n",
        "complete_sentence(\"I want to play bawling with cummins because i always liked him as a bowling\")\n",
        "complete_sentence(\"Tvbhjjbjbjbbab nv anhvhaghchvdejbbdmn nc n  nac xn jcjb jcejb  eacn cc  acc\")\n",
        "complete_sentence(\"jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Continuing sentence 'ronaldo because i always liked him as a footballer' ...\n",
            "...   even it of the stath my to the sable and the count of him and all you with the ceter had count, you at as the wite the state as the hid with has me, and the to the count one, and i was we stand sting\n",
            "\n",
            "Continuing sentence 'ronaldo because i always liked him as a footballer' ...\n",
            "...   to accripe the see had me be was my to know it i at one, but as he to be has and momere may of my to firth her as to her cloft the astant bes she of the be prest you one a tomy with the whily, and th\n",
            "\n",
            "Continuing sentence 'ronaldo because i always liked him as a footballer' ...\n",
            "...  s that i was and to and manctes to one stell of and the lother, and treat ran the biltoth he to the some the seemed that he can and hand the that the baary keep that the pire the rand the place how th\n",
            "\n",
            "Continuing sentence 'th dhoni because i always liked him as a cricketer' ...\n",
            "...  . there rear the was and in the stair was to was that i stand was the shack and me of the cating of the atty of the adlanged to my lest she be mach sher one to my all to my stiend when i was the bothi\n",
            "\n",
            "Continuing sentence 'th cummins because i always liked him as a bowling' ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "...  s to her in full from of it and the to at the what only to had adtienst of sised in was the lust was and in the datters her the minh a was the deal went were blead, i that draraked at she that and we \n",
            "\n",
            "Continuing sentence 'hchvdejbbdmn nc n  nac xn jcjb jcejb  eacn cc  acc' ...\n",
            "...  on of he stole--when the boback in he her the the to pince the tapated of the sole to the drein i the seemed which i carn that is only stast the stime of in shard the stering the wurt pient her to was\n",
            "\n",
            "Continuing sentence 'jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj' ...\n",
            "...  '; the would and so the was could for of the fall his redvered her to before the wre were me to were a sittren to the pawt i am so seemed her the sume mine, and the bodder. the sear far had and fall t\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQBfHwCJUmh2"
      },
      "source": [
        "### TODO: Add 3 more sentences to complete. Think about what types of sentences would be interesting to test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtcRdawJPE9s"
      },
      "source": [
        "# Biased data -> biased model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ij4obo3uPKOq",
        "outputId": "334ce168-c96a-4ec2-d8b1-236533d0a045",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "complete_sentence(\"    was the thiefs answer, to which the man replied \")\n",
        "complete_sentence(\"    was the thiefs answer, to which the woman replied \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Continuing sentence '  was the thiefs answer, to which the man replied ' ...\n",
            "...  to the best, and now the or few sound to the escian of the stile plowhiness, and his like, the sstarting and had the count. i have san interated as he had site that it was form one of charner. she had\n",
            "\n",
            "Continuing sentence 'was the thiefs answer, to which the woman replied ' ...\n",
            "...  to me, and the his more in the bidd a thing of the patient. i decrided the door and we sat and sitting that i have treeted to be all the hear, and all dilids and he had been remore a short and which t\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}