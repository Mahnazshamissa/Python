{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "asigmo_ex3_VGG19 .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahnazshamissa/Python/blob/main/asigmo_ex3_VGG19_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cQf_bBTm7r7"
      },
      "source": [
        "# Lab exercise 3\n",
        "\n",
        "\n",
        "Per Group:\n",
        "- 1.   Create a teams-meeting where one person opens the colab notebook and shares the screen (preferably a different person than yesterday)\n",
        "2.   Don't unfreeze the pretrained ResNet50 and train it together with the last layer from scratch on 20 epochs. What's the best validation accuracy and test accuracy you get?\n",
        "3.   Pretrain the output layer on 20 epochs, then unfreeze all layers and train it for 10 epochs. What's the best validation accuracy and test accuracy you get?\n",
        "4.   Pretrain the output layer on 20 epochs, then unfreeze only the first 10 layers and train it for 10 epochs. What's the best validation accuracy and test accuracy you get?\n",
        "5.   Think about why your network performed better or worse compared to the ~94% accuracy of the baseline network\n",
        "6.   Change the ResNet50 backbone to a ```EfficientNetB4```(group A and C) or ```VGG19``` (group D and E) and train only the output layer. What's the best validation accuracy and test accuracy you get? (don't forget to also change the preprocessing function)\n",
        "7.   In each group channel answer the questions below\n",
        "\n",
        "**Warning:** In steps 3 to 5 make sure you overwrite the model and don't continue training on the model from the previous step!\n",
        "\n",
        "\n",
        "**Questions**\n",
        "1.  Assuming a ResNet50 training step with a batchsize of 64 takes around 900ms, how long would one training epoch take on ImageNet (1.3 million training images)?\n",
        "2. How long would it then take to train the ResNet50 for 100 epochs?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_UwFycd-VvW",
        "outputId": "760a12e1-a136-485b-bb00-1bf755b2bfaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "imageNetSize =1300000\n",
        "imageNetBatches = imageNetSize / 64\n",
        "timePerBatch = 0.9 #seconds\n",
        "totalTime = imageNetBatches * timePerBatch\n",
        "timePerEpochInHours = totalTime/(60*60)\n",
        "print(\"time to run one epoch with all images in imageNet: %f hours\"%timePerEpochInHours)\n",
        "totalTimeTraining = timePerEpochInHours * 100 / 24\n",
        "print(\"time to run 100 epocsh with all images in imageNet: %f days\"%totalTimeTraining)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time to run one epoch with all images in imageNet: 5.078125 hours\n",
            "time to run 100 epocsh with all images in imageNet: 21.158854 days\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB-q8XI3NPWq"
      },
      "source": [
        "## Setup notebook environment\n",
        "\n",
        "Make sure the Colab environment has a GPU enabled *Edit->Notebook Settings->Hardware accelerator->Choose GPU*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aG_RlnMI7Fj",
        "outputId": "3674ff20-3963-42d8-ee07-7354875b1836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Oct 29 10:24:52 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc8c_aozNWpg"
      },
      "source": [
        "Download the dataset first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGa7l7SjNZFe",
        "outputId": "c6a5da42-408c-484e-ed89-9061618199e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! wget https://pub.ist.ac.at/~mlechner/datasets/f8d.tar.gz\n",
        "! tar -xf f8d.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-29 10:24:58--  https://pub.ist.ac.at/~mlechner/datasets/f8d.tar.gz\n",
            "Resolving pub.ist.ac.at (pub.ist.ac.at)... 81.223.84.195\n",
            "Connecting to pub.ist.ac.at (pub.ist.ac.at)|81.223.84.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76149807 (73M) [application/x-gzip]\n",
            "Saving to: ‘f8d.tar.gz’\n",
            "\n",
            "f8d.tar.gz          100%[===================>]  72.62M  6.09MB/s    in 11s     \n",
            "\n",
            "2020-10-29 10:25:09 (6.61 MB/s) - ‘f8d.tar.gz’ saved [76149807/76149807]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkhCfNnTOdTJ"
      },
      "source": [
        "Import python libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBF6BqbgNbII"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlKQkw7ZOhBQ"
      },
      "source": [
        "## Step 1: Define datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZt14huyNguI",
        "outputId": "ecbbc5cf-0830-4253-c78d-fcccf31c698c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  \"f8d/test\", shuffle=False, batch_size=128, image_size=(256, 256),\n",
        ")\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  \"f8d/training\",\n",
        "  shuffle=True,\n",
        "  batch_size=64,\n",
        "  image_size=(256, 256),\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=1020202,\n",
        ")\n",
        "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  \"f8d/training\",\n",
        "  shuffle=True,\n",
        "  batch_size=128,\n",
        "  image_size=(256, 256),\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=1020202,\n",
        ")\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "valid_dataset = valid_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 640 files belonging to 8 classes.\n",
            "Found 1840 files belonging to 8 classes.\n",
            "Using 1472 files for training.\n",
            "Found 1840 files belonging to 8 classes.\n",
            "Using 368 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HtXmk8mOrh4"
      },
      "source": [
        "## Step 2 and 3: Define model and objective"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onpKWbSNNjCg",
        "outputId": "085c2c63-5528-4d1a-d4e0-e8b126e47226",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pretrained_model = tf.keras.applications.VGG19(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Input(shape=(256,256,3)),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomCrop(224, 224),\n",
        "  tf.keras.layers.Lambda(lambda x: tf.keras.applications.vgg19.preprocess_input(x)),\n",
        "  pretrained_model,\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(8, activation=\"softmax\"),\n",
        "])\n",
        "pretrained_model.trainable=False\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "random_crop_2 (RandomCrop)   (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "lambda_2 (Lambda)            (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "vgg19 (Functional)           (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 8)                 4104      \n",
            "=================================================================\n",
            "Total params: 20,028,488\n",
            "Trainable params: 4,104\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXRe8j9zOvbw"
      },
      "source": [
        "## Step 4: Train the last layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Aes5WmpNlTN",
        "outputId": "99c5e077-8549-426e-f273-e76e7c4b97a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "training_log = model.fit(\n",
        "  train_dataset, epochs=20, validation_data=valid_dataset\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "23/23 [==============================] - 8s 368ms/step - loss: 4.9241 - sparse_categorical_accuracy: 0.3390 - val_loss: 2.5943 - val_sparse_categorical_accuracy: 0.5109\n",
            "Epoch 2/20\n",
            "23/23 [==============================] - 5s 198ms/step - loss: 1.8499 - sparse_categorical_accuracy: 0.6345 - val_loss: 1.4875 - val_sparse_categorical_accuracy: 0.6821\n",
            "Epoch 3/20\n",
            "23/23 [==============================] - 5s 199ms/step - loss: 1.0492 - sparse_categorical_accuracy: 0.7548 - val_loss: 1.1712 - val_sparse_categorical_accuracy: 0.7418\n",
            "Epoch 4/20\n",
            "23/23 [==============================] - 5s 199ms/step - loss: 0.7363 - sparse_categorical_accuracy: 0.8186 - val_loss: 0.9613 - val_sparse_categorical_accuracy: 0.7853\n",
            "Epoch 5/20\n",
            "23/23 [==============================] - 5s 201ms/step - loss: 0.5503 - sparse_categorical_accuracy: 0.8567 - val_loss: 0.8919 - val_sparse_categorical_accuracy: 0.8125\n",
            "Epoch 6/20\n",
            "23/23 [==============================] - 5s 200ms/step - loss: 0.4153 - sparse_categorical_accuracy: 0.8879 - val_loss: 0.8140 - val_sparse_categorical_accuracy: 0.8179\n",
            "Epoch 7/20\n",
            "23/23 [==============================] - 5s 198ms/step - loss: 0.3672 - sparse_categorical_accuracy: 0.8967 - val_loss: 0.7671 - val_sparse_categorical_accuracy: 0.8424\n",
            "Epoch 8/20\n",
            "23/23 [==============================] - 5s 200ms/step - loss: 0.2959 - sparse_categorical_accuracy: 0.9124 - val_loss: 0.7444 - val_sparse_categorical_accuracy: 0.8397\n",
            "Epoch 9/20\n",
            "23/23 [==============================] - 5s 200ms/step - loss: 0.2499 - sparse_categorical_accuracy: 0.9226 - val_loss: 0.7020 - val_sparse_categorical_accuracy: 0.8424\n",
            "Epoch 10/20\n",
            "23/23 [==============================] - 5s 200ms/step - loss: 0.2121 - sparse_categorical_accuracy: 0.9341 - val_loss: 0.6978 - val_sparse_categorical_accuracy: 0.8397\n",
            "Epoch 11/20\n",
            "23/23 [==============================] - 5s 199ms/step - loss: 0.1900 - sparse_categorical_accuracy: 0.9375 - val_loss: 0.6657 - val_sparse_categorical_accuracy: 0.8451\n",
            "Epoch 12/20\n",
            "23/23 [==============================] - 5s 198ms/step - loss: 0.1891 - sparse_categorical_accuracy: 0.9348 - val_loss: 0.6402 - val_sparse_categorical_accuracy: 0.8505\n",
            "Epoch 13/20\n",
            "23/23 [==============================] - 5s 199ms/step - loss: 0.1408 - sparse_categorical_accuracy: 0.9470 - val_loss: 0.6408 - val_sparse_categorical_accuracy: 0.8533\n",
            "Epoch 14/20\n",
            "23/23 [==============================] - 5s 199ms/step - loss: 0.1451 - sparse_categorical_accuracy: 0.9436 - val_loss: 0.6213 - val_sparse_categorical_accuracy: 0.8614\n",
            "Epoch 15/20\n",
            "23/23 [==============================] - 5s 199ms/step - loss: 0.1238 - sparse_categorical_accuracy: 0.9572 - val_loss: 0.6090 - val_sparse_categorical_accuracy: 0.8587\n",
            "Epoch 16/20\n",
            "23/23 [==============================] - 5s 199ms/step - loss: 0.1088 - sparse_categorical_accuracy: 0.9640 - val_loss: 0.6145 - val_sparse_categorical_accuracy: 0.8587\n",
            "Epoch 17/20\n",
            "23/23 [==============================] - 5s 199ms/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.6351 - val_sparse_categorical_accuracy: 0.8560\n",
            "Epoch 18/20\n",
            "23/23 [==============================] - 5s 201ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9660 - val_loss: 0.5971 - val_sparse_categorical_accuracy: 0.8614\n",
            "Epoch 19/20\n",
            "23/23 [==============================] - 5s 200ms/step - loss: 0.0718 - sparse_categorical_accuracy: 0.9749 - val_loss: 0.5800 - val_sparse_categorical_accuracy: 0.8641\n",
            "Epoch 20/20\n",
            "23/23 [==============================] - 5s 200ms/step - loss: 0.0697 - sparse_categorical_accuracy: 0.9810 - val_loss: 0.5711 - val_sparse_categorical_accuracy: 0.8641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIt6mEA-NnIY",
        "outputId": "645f29ec-041b-40f6-cda6-59cf91df6cf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"Best validation accuracy is {100*np.max(training_log.history['val_sparse_categorical_accuracy']):0.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best validation accuracy is 86.41%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eECMpKvLO4LJ"
      },
      "source": [
        "## Step 5: Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP1f7owVNohQ",
        "outputId": "6b23b14d-08ee-4e8d-8858-91de2f9e3d54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 228ms/step - loss: 0.6627 - sparse_categorical_accuracy: 0.8391\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.662731945514679, 0.839062511920929]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Jit-LJQpQYS"
      },
      "source": [
        "## Unfreeze the weights of the last 10 layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkGqdgVSVoeg"
      },
      "source": [
        "pretrained_model.trainable = True\n",
        "for l in pretrained_model.layers:\n",
        "  l.trainable=False\n",
        "for i in range(10):\n",
        "  pretrained_model.layers[-i].trainable=True\n",
        "  \n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.RMSprop(0.0001),\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5ma8maFV6kO"
      },
      "source": [
        "training_log2 = model.fit(\n",
        "  train_dataset, epochs=10, validation_data=valid_dataset\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBaBM5R9YVCw"
      },
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}